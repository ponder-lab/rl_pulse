{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulse sequence reward prediction with supervised learning\n",
    "_Written by Will Kaufman_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "# from rl_pulse.environments import spin_sys_discrete\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/2020-08/2020-08-21-143037/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_files = np.load(os.path.join(data_path, 'data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = npz_files['actions']\n",
    "rewards = npz_files['rewards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out why I can't load the model...\n",
    "model = keras.models.load_model(os.path.join(data_path, 'my_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = int(np.floor(rewards.argmax() / 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sample = tf.convert_to_tensor(actions[index, ...], dtype=tf.float32)\n",
    "r_sample = tf.convert_to_tensor(rewards[index, ...], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_pred = tf.squeeze(model(tf.expand_dims(a_sample, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = r_sample - tf.squeeze(r_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print(a_sample)\n",
    "    print(r_sample)\n",
    "    print(r_pred)\n",
    "    print(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action0 = np.zeros((24,5))\n",
    "for i, a in enumerate([4, 1, 2, 4, 3, 0] * 4):\n",
    "    action0[i,a] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action1 = np.zeros((24,5))\n",
    "for i, a in enumerate([4] * 24):\n",
    "    action1[i,a] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action2 = np.zeros((24,5))\n",
    "for i, a in enumerate([1, 4, 0, 2, 4, 3, 2, 4, 3, 1, 4, 0] * 2):  # 4, 0, 2, 4, 3, 1\n",
    "    action2[i,a] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward0 = tf.squeeze(model(tf.expand_dims(action0, axis=0)))\n",
    "reward1 = tf.squeeze(model(tf.expand_dims(action1, axis=0)))\n",
    "reward2 = tf.squeeze(model(tf.expand_dims(action2, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(reward0)\n",
    "plt.plot(reward1)\n",
    "plt.plot(reward2)\n",
    "plt.legend(['WHH-4', 'delay', '???'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working backwards: optimizing reward by gradient ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tf.random.uniform(shape=(1,24,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at [this](https://www.tensorflow.org/tutorials/generative/deepdream#calculate_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(actions, model):\n",
    "    # assuming actions has batch dimension\n",
    "    rewards = model(actions)\n",
    "    loss_reward = -tf.reduce_sum(rewards[:,-1,:])\n",
    "    \n",
    "    # regularization to push values towards 0 or 1\n",
    "    reg = 1e-2 * tf.reduce_sum(actions * (1 - actions))\n",
    "    \n",
    "    # make actions look action-like by requiring sum of row to be close to 1\n",
    "    action_reg = 1e-2 * tf.reduce_sum(tf.abs(tf.reduce_sum(actions, 2) - 1))\n",
    "    \n",
    "    return loss_reward + reg + action_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_random = tf.random.uniform(shape=(1,24,5))\n",
    "action_random = tf.zeros(shape=(1,24,5)) + .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(50):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(action_random)\n",
    "        loss = calc_loss(action_random, model)\n",
    "\n",
    "    gradients = tape.gradient(loss, action_random)\n",
    "    # print(gradients)\n",
    "    action_random = action_random - gradients * 1e-1\n",
    "    action_random = tf.clip_by_value(action_random, 0, 1)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.convert_to_tensor(np.array([[[0,1,0,0,0]]], dtype=np.float32))\n",
    "b = action_random[:,1:,:]\n",
    "action_random = tf.concat([a, b], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.printoptions(precision=3, suppress=True):\n",
    "    print(action_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(action_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = model.get_layers()[0]  # or something like that, I forget..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1.set_weights(lstm.get_weights())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
