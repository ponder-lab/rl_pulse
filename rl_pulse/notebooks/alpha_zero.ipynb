{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero implementation for pulse sequence design\n",
    "_Will Kaufman, December 2020_\n",
    "\n",
    "[Dalgaard et. al. (2020)](https://www.nature.com/articles/s41534-019-0241-0) applied this approach to constructing shaped pulses (as I understand it), but in theory this should be as applicable to pulse sequence design, if not more so. The original [AlphaZero paper](https://science.sciencemag.org/content/362/6419/1140.full) and the [AlphaGo Zero paper](https://www.nature.com/articles/nature24270) are useful resources.\n",
    "\n",
    "The general idea behind AlphaZero (as I understand it) is to do a \"smart\" tree search that balances previous knowledge (the policy), curiosity in unexplored branches, and high-value branches. My thought is that this can be improved with AHT (i.e. knowing that by the end of the pulse sequence, the pulse sequence must be cyclic (the overall frame transformation must be identity) and there must be equal times spent on each axis). This will provide a hard constraint that will (hopefully) speed up search.\n",
    "\n",
    "## System installation\n",
    "\n",
    "Make sure the following packages are installed\n",
    "\n",
    "- `numpy`\n",
    "- `scipy`\n",
    "- `qutip`\n",
    "- `pytorch`\n",
    "- `tensorboard`\n",
    "\n",
    "## TODO\n",
    "- [ ] Collect all hyperparameters up top or in config (e.g. how many pulse sequences to collect data from)\n",
    "- [ ] Speed up LSTM (save hidden state, batch parallel pulse sequences, other?)\n",
    "- [ ] Figure out GPU utilization (if I can...)\n",
    "- [ ] Look into collecting training data and training continuously\n",
    "- [ ] Change dirichlet noise to match number of possible moves (5 for now, eventually 24)\n",
    "- [ ] Dynamically figure out how many CPUs there are available, and set pool to use that\n",
    "- [ ] Mess around with hyperparameters (e.g. in config object), see if performance improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [ ] Add other changes on github project page (lots of documenting algo run)\n",
    "- [ ] Run it on Discovery, hope it works!\n",
    "- [ ] Clean up code, add tests, make sure everything is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import torch.multiprocessing as mp\n",
    "import importlib\n",
    "\n",
    "from datetime import datetime\n",
    "import random\n",
    "from time import sleep\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "import pulse_sequences as ps\n",
    "import alpha_zero as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(az)\n",
    "# importlib.reload(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 2  # 32\n",
    "num_collect = 2  # 2000\n",
    "num_collect_initial = 2  # 5000\n",
    "batch_size = 64  #2048\n",
    "num_iters = 100  # 1000\n",
    "\n",
    "max_sequence_length = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the spin system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 1e-2  # time is relative to chemical shift strength\n",
    "pulse_width = 1e-3\n",
    "N = 3  # number of spins\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, Z = ps.get_collective_spin(N)\n",
    "# Hsys_ensemble = [ps.get_Hsys(N) for _ in range(ensemble_size)]\n",
    "# pulses_ensemble = [\n",
    "#     ps.get_pulses(H, X, Y, Z, pulse_width, delay, rot_error=0.01) for H in Hsys_ensemble\n",
    "# ]\n",
    "# Utarget = qt.identity(Hsys_ensemble[0].dims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utarget = qt.tensor([qt.identity(2)] * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smarter search with MCTS\n",
    "\n",
    "Following the [supplementary materials description under \"Search\"](https://science.sciencemag.org/content/sci/suppl/2018/12/05/362.6419.1140.DC1/aar6404-Silver-SM.pdf) to do rollouts and backpropagate information. All of the relevant code for the alpha zero algorithm is in alpha_zero.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Inspired by [this pytorch tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html). This will store data collected by MCTS rollouts. The data is the state (the pulse sequence applied so far), the empirical probability distribution based on visit counts, and the value from the end of the pulse sequence.\n",
    "\n",
    "Based on a rough idea of what was done with AlphaGo Zero and AlphaZero, I think I need to collect a lot of data and train a lot with each iteration. In AlphaGo Zero, they collected 25,000 games per iteration and trained with minibatch sizes of 2048 (training continuously I think)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb = az.ReplayBuffer(int(1e5))  # 1e6\n",
    "buffer_size = int(1e5)  # 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of saving data in a reasonable way (and using RNN), the state is represented by a sequence, where 0 indicates the start of sequence, and 1-5 are the possible pulses (1: delay, 2: x, etc...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill replay buffer with inital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_no_net(proc_num, buffer, index, lock, buffer_size, ps_count):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        proc_num: Which process number this is (for debug purposes)\n",
    "        buffer (mp.managers.List): A shared replay buffer\n",
    "        index (mp.managers.Value): The current index for the buffer\n",
    "        lock (mp.managers.RLock): Lock object to prevent overwriting\n",
    "            data from different threads\n",
    "        buffer_size (int): The maximum size of the buffer\n",
    "        ps_count (Value): Shared count of how many pulse sequences have\n",
    "            been constructed\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'collecting data without network ({proc_num})')\n",
    "    config = az.Config()\n",
    "    ps_config = ps.PulseSequenceConfig(N=N, ensemble_size=ensemble_size,\n",
    "                                       max_sequence_length=max_sequence_length,\n",
    "                                       Utarget=Utarget,\n",
    "                                       pulse_width=pulse_width, delay=delay)\n",
    "    output = az.make_sequence(config, ps_config, network=None, rng=ps_config.rng)\n",
    "    output_tensors = az.convert_stats_to_tensors(output)\n",
    "    with lock:\n",
    "        ps_count.value += 1\n",
    "    for obs in output_tensors:\n",
    "        with lock:\n",
    "            if len(buffer) < buffer_size:\n",
    "                buffer.append(obs)\n",
    "            else:\n",
    "                buffer[index.value] = obs\n",
    "            index.value += 1\n",
    "            if index.value >= buffer_size:\n",
    "                index.value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data without network (0)\n",
      "collecting data without network (1)\n",
      "collecting data without network (2)\n",
      "collecting data without network (3)\n",
      "done gathering initial data!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with mp.Manager() as manager:\n",
    "        buffer = manager.list()  #[None] * buffer_size\n",
    "        index = manager.Value(typecode='i', value=0)\n",
    "        lock = manager.RLock()\n",
    "        workers = []\n",
    "        for i in range(4):\n",
    "            workers.append(mp.Process(target=collect_data_no_net,\n",
    "                                      args=(i, buffer, index, lock, buffer_size)))\n",
    "            workers[-1].start()\n",
    "        for w in workers:\n",
    "            w.join()\n",
    "        print('done gathering initial data!')\n",
    "        l = list(buffer)  # to save a non-shared copy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS with policy and value networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = az.Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing networks with replay buffer data\n",
    "\n",
    "See [this doc](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) for writing training loss to tensorboard data, and [this doc](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference) for saving/loading models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "Setting up this algorithm to run in parallel is quite important. I'm using [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) to handle the parallelism, and it looks like pytorch also has a similar API for moving Tensors around. With 2 processors on my laptop, speedup is about 90% (not bad...).\n",
    "\n",
    "Want to set random seed for each process, otherwise you end up getting all the same results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(proc_num, buffer, index, lock, buffer_size, net, ps_count):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ps_count (Value): A shared count of how many pulse sequences have been\n",
    "            constructed so far\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'collecting data ({proc_num})')\n",
    "    config = az.Config()\n",
    "    config.num_simulations = 250\n",
    "    ps_config = ps.PulseSequenceConfig(Utarget=Utarget, N=N, ensemble_size=ensemble_size,\n",
    "                                       max_sequence_length=max_sequence_length,\n",
    "                                       pulse_width=pulse_width, delay=delay)\n",
    "    for _ in range(4):\n",
    "        ps_config.reset()\n",
    "        output = az.make_sequence(config, ps_config, network=net, rng=ps_config.rng)\n",
    "        output_tensors = az.convert_stats_to_tensors(output)\n",
    "        with lock:\n",
    "            ps_count.value += 1\n",
    "        for obs in output_tensors:\n",
    "            with lock:\n",
    "                if len(buffer) < buffer_size:\n",
    "                    buffer.append(obs)\n",
    "                else:\n",
    "                    buffer[index.value] = obs\n",
    "                index.value += 1\n",
    "                if index.value >= buffer_size:\n",
    "                    index.value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting data (0)\n",
      "collecting data (1)\n",
      "collecting data (2)\n",
      "collecting data (3)\n",
      "done gathering initial data!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with mp.Manager() as manager:\n",
    "        buffer = manager.list()  #[None] * 500\n",
    "        index = manager.Value(typecode='i', value=0)\n",
    "        lock = manager.RLock()\n",
    "        # get network\n",
    "        net = az.Network()\n",
    "        net.share_memory()\n",
    "        workers = []\n",
    "        for i in range(4):\n",
    "            workers.append(mp.Process(target=collect_data,\n",
    "                                      args=(i, buffer, index, lock, buffer_size, net)))\n",
    "            workers[-1].start()\n",
    "        for w in workers:\n",
    "            w.join()\n",
    "        print('done gathering data!')\n",
    "        l = list(buffer)  # save a non-shared copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(proc_num, buffer, net, global_step, ps_count):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        buffer (mp.managers.list): Replay buffer, list of (state, probability, value).\n",
    "        global_step (mp.managers.Value): Counter to keep track of training iterations\n",
    "        writer (SummaryWriter): Write losses to log\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'started training process ({proc_num})')\n",
    "    writer = SummaryWriter()\n",
    "    net_optimizer = optim.Adam(net.parameters(),)\n",
    "    for i in range(num_iters):  # number of training iterations\n",
    "        if i % 100 == 0:\n",
    "            print(datetime.now(), 'saving network...')\n",
    "            # save network parameters to file\n",
    "            if not os.path.exists('network'):\n",
    "                os.makedirs('network')\n",
    "            torch.save(net.state_dict(), f'network/{i:07.0f}-network')\n",
    "        if len(buffer) < batch_size:\n",
    "            print(datetime.now(), 'not enough data yet, sleeping...')\n",
    "            sleep(5)\n",
    "            continue\n",
    "        net_optimizer.zero_grad()\n",
    "        # sample minibatch from replay buffer\n",
    "        minibatch = random.sample(list(buffer), batch_size)\n",
    "        states, probabilities, values = zip(*minibatch)\n",
    "        probabilities = torch.stack(probabilities)\n",
    "        values = torch.stack(values)\n",
    "        packed_states = az.pad_and_pack(states)\n",
    "        # evaluate network\n",
    "        policy_outputs, value_outputs, _ = net(packed_states)\n",
    "        policy_loss = -1 / \\\n",
    "            len(states) * torch.sum(probabilities * torch.log(policy_outputs))\n",
    "        value_loss = F.mse_loss(value_outputs, values)\n",
    "        loss = policy_loss + value_loss\n",
    "        loss.backward()\n",
    "        net_optimizer.step()\n",
    "        # write losses to log\n",
    "        writer.add_scalar('training_policy_loss',\n",
    "                          policy_loss, global_step=global_step.value)\n",
    "        writer.add_scalar('training_value_loss',\n",
    "                          value_loss, global_step=global_step.value)\n",
    "        # every 10 iterations, add histogram of replay buffer values\n",
    "        # and save network to file...\n",
    "        if i % 10 == 0:\n",
    "            print(datetime.now(), f'updated network (iteration {i})',\n",
    "                  f'pulse_sequence_count: {ps_count.value}')\n",
    "            _, _, values = zip(*list(buffer))\n",
    "            values = torch.stack(values).squeeze()\n",
    "            writer.add_histogram('buffer_values', values, global_step=global_step.value)\n",
    "            writer.add_scalar('pulse_sequence_count', ps_count.value, global_step.value)\n",
    "        global_step.value += 1\n",
    "        sleep(.5)  # TODO remove this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    with mp.Manager() as manager:\n",
    "        buffer = manager.list()\n",
    "        index = manager.Value(typecode='i', value=0)\n",
    "        global_step = manager.Value('i', 0)\n",
    "        ps_count = manager.Value('i', 0)\n",
    "        lock = manager.RLock()\n",
    "        # get network\n",
    "        net = az.Network()\n",
    "        net.share_memory()\n",
    "        collectors = []\n",
    "        for i in range(4):\n",
    "            c = mp.Process(target=collect_data_no_net,\n",
    "                           args=(i, buffer, index, lock, buffer_size, ps_count))\n",
    "            c.start()\n",
    "            collectors.append(c)\n",
    "        trainer = mp.Process(target=train_process,\n",
    "                             args=(4, buffer, net, global_step, ps_count))\n",
    "        trainer.start()\n",
    "        # start data collectors with network\n",
    "        for i in range(5, 9):\n",
    "            c = mp.Process(target=collect_data,\n",
    "                           args=(i, buffer, index, lock, buffer_size, net, ps_count))\n",
    "            c.start()\n",
    "            collectors.append(c)\n",
    "        for p in collectors:\n",
    "            p.join()\n",
    "        print('all collectors are joined')\n",
    "        trainer.join()\n",
    "        print('trainer is joined')\n",
    "        l = list(buffer)  # save a non-shared copy\n",
    "        print('done gathering data!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that sharing the neural network behaves as expected! Training updates the weights, and those updated weights are reflected in each of the data collection processes. Neat!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
