{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero implementation for pulse sequence design\n",
    "_Will Kaufman, December 2020_\n",
    "\n",
    "[Dalgaard et. al. (2020)](https://www.nature.com/articles/s41534-019-0241-0) applied this approach to constructing shaped pulses (as I understand it), but in theory this should be as applicable to pulse sequence design, if not more so. The original [AlphaZero paper](https://science.sciencemag.org/content/362/6419/1140.full) and the [AlphaGo Zero paper](https://www.nature.com/articles/nature24270) are useful resources.\n",
    "\n",
    "The general idea behind AlphaZero (as I understand it) is to do a \"smart\" tree search that balances previous knowledge (the policy), curiosity in unexplored branches, and high-value branches. My thought is that this can be improved with AHT (i.e. knowing that by the end of the pulse sequence, the pulse sequence must be cyclic (the overall frame transformation must be identity) and there must be equal times spent on each axis). This will provide a hard constraint that will (hopefully) speed up search.\n",
    "\n",
    "## System installation\n",
    "\n",
    "Make sure the following packages are installed\n",
    "\n",
    "- `numpy`\n",
    "- `scipy`\n",
    "- `qutip`\n",
    "- `pytorch`\n",
    "- `tensorboard`\n",
    "\n",
    "## TODO\n",
    "- [ ] Collect all hyperparameters up top or in config (e.g. how many pulse sequences to collect data from)\n",
    "- [ ] Speed up LSTM (save hidden state, batch parallel pulse sequences, other?)\n",
    "- [ ] Figure out GPU utilization (if I can...)\n",
    "- [ ] Look into collecting training data and training continuously\n",
    "- [ ] Change dirichlet noise to match number of possible moves (5 for now, eventually 24)\n",
    "- [ ] Dynamically figure out how many CPUs there are available, and set pool to use that\n",
    "- [ ] Mess around with hyperparameters (e.g. in config object), see if performance improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [ ] Add other changes on github project page (lots of documenting algo run)\n",
    "- [ ] Run it on Discovery, hope it works!\n",
    "- [ ] Clean up code, add tests, make sure everything is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "from time import sleep\n",
    "import qutip as qt\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "import pulse_sequences as ps\n",
    "import alpha_zero as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(az)\n",
    "# importlib.reload(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_no_net_procs = 15  # 15\n",
    "collect_no_net_count = 700  # 700\n",
    "collect_procs = 15  # 15\n",
    "collect_count = 1000  # 1000\n",
    "\n",
    "buffer_size = int(1e6)  # 1e6\n",
    "batch_size = 2048  # 2048\n",
    "num_iters = int(800e3)  # 800e3\n",
    "\n",
    "max_sequence_length = 48\n",
    "\n",
    "print_every = 100  # 100\n",
    "save_every = 1000  # 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the spin system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 1e-2  # time is relative to chemical shift strength\n",
    "pulse_width = 1e-3\n",
    "N = 3  # number of spins\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, Z = ps.get_collective_spin(N)\n",
    "# Hsys_ensemble = [ps.get_Hsys(N) for _ in range(ensemble_size)]\n",
    "# pulses_ensemble = [\n",
    "#     ps.get_pulses(H, X, Y, Z, pulse_width, delay, rot_error=0.01) for H in Hsys_ensemble\n",
    "# ]\n",
    "# Utarget = qt.identity(Hsys_ensemble[0].dims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utarget = qt.tensor([qt.identity(2)] * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smarter search with MCTS\n",
    "\n",
    "Following the [supplementary materials description under \"Search\"](https://science.sciencemag.org/content/sci/suppl/2018/12/05/362.6419.1140.DC1/aar6404-Silver-SM.pdf) to do rollouts and backpropagate information. All of the relevant code for the alpha zero algorithm is in alpha_zero.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of saving data in a reasonable way (and using RNN), the state is represented by a sequence, where 0 indicates the start of sequence, and 1-5 are the possible pulses (1: delay, 2: x, etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function make_sequence in module alpha_zero:\n",
      "\n",
      "make_sequence(config, ps_config, network=None, rng=None)\n",
      "    Start with no pulses, do MCTS until a sequence of length\n",
      "    sequence_length is made.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(az.make_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = az.make_sequence(az.Config(), ps.PulseSequenceConfig(Utarget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05160428607800024"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill replay buffer with inital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_no_net(proc_num, buffer, index, lock, buffer_size, ps_count):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        proc_num: Which process number this is (for debug purposes)\n",
    "        buffer (mp.managers.List): A shared replay buffer\n",
    "        index (mp.managers.Value): The current index for the buffer\n",
    "        lock (mp.managers.RLock): Lock object to prevent overwriting\n",
    "            data from different threads\n",
    "        buffer_size (int): The maximum size of the buffer\n",
    "        ps_count (Value): Shared count of how many pulse sequences have\n",
    "            been constructed\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'collecting data without network ({proc_num})')\n",
    "    config = az.Config()\n",
    "    ps_config = ps.PulseSequenceConfig(N=N, ensemble_size=ensemble_size,\n",
    "                                       max_sequence_length=max_sequence_length,\n",
    "                                       Utarget=Utarget,\n",
    "                                       pulse_width=pulse_width, delay=delay)\n",
    "    for i in range(collect_no_net_count):\n",
    "        ps_config.reset()\n",
    "        output = az.make_sequence(config, ps_config, network=None, rng=ps_config.rng)\n",
    "        if output[-1][2] > 2:\n",
    "            print(datetime.now(),\n",
    "                  f'candidate pulse sequence from {proc_num}',\n",
    "                  output[-1])\n",
    "        output_tensors = az.convert_stats_to_tensors(output)\n",
    "        with lock:\n",
    "            ps_count.value += 1\n",
    "        for obs in output_tensors:\n",
    "            with lock:\n",
    "                if len(buffer) < buffer_size:\n",
    "                    buffer.append(obs)\n",
    "                else:\n",
    "                    buffer[index.value] = obs\n",
    "                index.value += 1\n",
    "                if index.value >= buffer_size:\n",
    "                    index.value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with mp.Manager() as manager:\n",
    "#         buffer = manager.list()  #[None] * buffer_size\n",
    "#         index = manager.Value(typecode='i', value=0)\n",
    "#         lock = manager.RLock()\n",
    "#         workers = []\n",
    "#         for i in range(4):\n",
    "#             workers.append(mp.Process(target=collect_data_no_net,\n",
    "#                                       args=(i, buffer, index, lock, buffer_size)))\n",
    "#             workers[-1].start()\n",
    "#         for w in workers:\n",
    "#             w.join()\n",
    "#         print('done gathering initial data!')\n",
    "#         l = list(buffer)  # to save a non-shared copy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS with policy and value networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = az.Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing networks with replay buffer data\n",
    "\n",
    "See [this doc](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) for writing training loss to tensorboard data, and [this doc](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference) for saving/loading models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "Setting up this algorithm to run in parallel is quite important. I'm using [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) to handle the parallelism, and it looks like pytorch also has a similar API for moving Tensors around. With 2 processors on my laptop, speedup is about 90% (not bad...).\n",
    "\n",
    "Want to set random seed for each process, otherwise you end up getting all the same results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(proc_num, buffer, index, lock, buffer_size, net, ps_count):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ps_count (Value): A shared count of how many pulse sequences have been\n",
    "            constructed so far\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'collecting data ({proc_num})')\n",
    "    config = az.Config()\n",
    "    config.num_simulations = 250\n",
    "    ps_config = ps.PulseSequenceConfig(Utarget=Utarget, N=N,\n",
    "                                       ensemble_size=ensemble_size,\n",
    "                                       max_sequence_length=max_sequence_length,\n",
    "                                       pulse_width=pulse_width, delay=delay)\n",
    "    for _ in range(collect_count):\n",
    "        ps_config.reset()\n",
    "        output = az.make_sequence(config, ps_config, network=net, rng=ps_config.rng)\n",
    "        if output[-1][2] > 2:\n",
    "            print(datetime.now(),\n",
    "                  f'candidate pulse sequence from {proc_num}',\n",
    "                  output[-1])\n",
    "        output_tensors = az.convert_stats_to_tensors(output)\n",
    "        with lock:\n",
    "            ps_count.value += 1\n",
    "        for obs in output_tensors:\n",
    "            with lock:\n",
    "                if len(buffer) < buffer_size:\n",
    "                    buffer.append(obs)\n",
    "                else:\n",
    "                    buffer[index.value] = obs\n",
    "                index.value += 1\n",
    "                if index.value >= buffer_size:\n",
    "                    index.value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with mp.Manager() as manager:\n",
    "#         buffer = manager.list()  #[None] * 500\n",
    "#         index = manager.Value(typecode='i', value=0)\n",
    "#         lock = manager.RLock()\n",
    "#         # get network\n",
    "#         net = az.Network()\n",
    "#         net.share_memory()\n",
    "#         workers = []\n",
    "#         for i in range(4):\n",
    "#             workers.append(mp.Process(target=collect_data,\n",
    "#                                       args=(i, buffer, index, lock, buffer_size, net)))\n",
    "#             workers[-1].start()\n",
    "#         for w in workers:\n",
    "#             w.join()\n",
    "#         print('done gathering data!')\n",
    "#         l = list(buffer)  # save a non-shared copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(proc_num, buffer, net, global_step, ps_count):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        buffer (mp.managers.list): Replay buffer,\n",
    "            list of (state, probability, value).\n",
    "        global_step (mp.managers.Value): Counter to keep track\n",
    "            of training iterations\n",
    "        writer (SummaryWriter): Write losses to log\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'started training process ({proc_num})')\n",
    "    writer = SummaryWriter()\n",
    "    net_optimizer = optim.Adam(net.parameters(),)\n",
    "    for i in range(num_iters):  # number of training iterations\n",
    "        if i % save_every == 0:\n",
    "            print(datetime.now(), 'saving network...')\n",
    "            # save network parameters to file\n",
    "            if not os.path.exists('network'):\n",
    "                os.makedirs('network')\n",
    "            torch.save(net.state_dict(), f'network/{i:07.0f}-network')\n",
    "        if len(buffer) < batch_size:\n",
    "            print(datetime.now(), 'not enough data yet, sleeping...')\n",
    "            sleep(5)\n",
    "            continue\n",
    "        elif len(buffer) < 1e4:\n",
    "            sleep(.5)  # put on the brakes a bit, don't tear through the data\n",
    "        net_optimizer.zero_grad()\n",
    "        # sample minibatch from replay buffer\n",
    "        minibatch = random.sample(list(buffer), batch_size)\n",
    "        states, probabilities, values = zip(*minibatch)\n",
    "        probabilities = torch.stack(probabilities)\n",
    "        values = torch.stack(values)\n",
    "        packed_states = az.pad_and_pack(states)\n",
    "        # evaluate network\n",
    "        policy_outputs, value_outputs, _ = net(packed_states)\n",
    "        policy_loss = -1 / \\\n",
    "            len(states) * torch.sum(probabilities * torch.log(policy_outputs))\n",
    "        value_loss = F.mse_loss(value_outputs, values)\n",
    "        loss = policy_loss + value_loss\n",
    "        loss.backward()\n",
    "        net_optimizer.step()\n",
    "        # write losses to log\n",
    "        writer.add_scalar('training_policy_loss',\n",
    "                          policy_loss, global_step=global_step.value)\n",
    "        writer.add_scalar('training_value_loss',\n",
    "                          value_loss, global_step=global_step.value)\n",
    "        # every 10 iterations, add histogram of replay buffer values\n",
    "        # and save network to file...\n",
    "        if i % print_every == 0:\n",
    "            print(datetime.now(), f'updated network (iteration {i})',\n",
    "                  f'pulse_sequence_count: {ps_count.value}')\n",
    "            _, _, values = zip(*list(buffer))\n",
    "            values = torch.stack(values).squeeze()\n",
    "            writer.add_histogram('buffer_values', values, global_step=global_step.value)\n",
    "            writer.add_scalar('pulse_sequence_count', ps_count.value, global_step.value)\n",
    "        global_step.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-24 13:59:43.046960 collecting data without network (0)\n",
      "2021-01-24 13:59:43.073697 2021-01-24 13:59:43.082064 collecting data without network (1)started training process (4)\n",
      "\n",
      "2021-01-24 13:59:43.132382 saving network...\n",
      "2021-01-24 13:59:43.196518 not enough data yet, sleeping...\n",
      "2021-01-24 13:59:48.226922 not enough data yet, sleeping...\n",
      "2021-01-24 13:59:58.242179 updated network (iteration 10) pulse_sequence_count: 2\n",
      "2021-01-24 14:00:04.836921 updated network (iteration 20) pulse_sequence_count: 4\n",
      "2021-01-24 14:00:11.853371 updated network (iteration 30) pulse_sequence_count: 6\n",
      "2021-01-24 14:00:19.214673 updated network (iteration 40) pulse_sequence_count: 8\n",
      "2021-01-24 14:00:27.092816 updated network (iteration 50) pulse_sequence_count: 9\n",
      "2021-01-24 14:00:27.506723 collecting data (0)\n",
      "2021-01-24 14:00:27.513130 collecting data (1)\n",
      "2021-01-24 14:00:35.746970 updated network (iteration 60) pulse_sequence_count: 10\n",
      "2021-01-24 14:00:44.907221 updated network (iteration 70) pulse_sequence_count: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-235:\n",
      "Process Process-236:\n",
      "Process Process-237:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-105-07866c79996b>\", line 15, in collect_data\n",
      "    output = az.make_sequence(config, ps_config, network=net, rng=ps_config.rng)\n",
      "  File \"<ipython-input-106-5de872bd9316>\", line 52, in train_process\n",
      "    sleep(.5)  # TODO remove this\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 500, in make_sequence\n",
      "    sequence_funcs=sequence_funcs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-7ca57c2e562e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mcollectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all collectors are joined'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 298, in run_mcts\n",
      "    pulse, node = select_child(config, node)\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 363, in select_child\n",
      "    for pulse in node.children\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 363, in <genexpr>\n",
      "    for pulse in node.children\n",
      "  File \"<ipython-input-105-07866c79996b>\", line 15, in collect_data\n",
      "    output = az.make_sequence(config, ps_config, network=net, rng=ps_config.rng)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 371, in ucb_score\n",
      "    pb_c *= np.sqrt(parent.visit_count) / (child.visit_count + 1)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 500, in make_sequence\n",
      "    sequence_funcs=sequence_funcs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 303, in run_mcts\n",
      "    sequence_funcs=sequence_funcs)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 327, in evaluate\n",
      "    policy, value, _ = get_inference(sequence_tuple)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 487, in get_inference\n",
      "    (policy, value, h) = network(state, h_0=h)\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 232, in forward\n",
      "    value = self.value(x)\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 730, in _call_impl\n",
      "    self._forward_hooks.values()):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with mp.Manager() as manager:\n",
    "        buffer = manager.list()\n",
    "        index = manager.Value(typecode='i', value=0)\n",
    "        global_step = manager.Value('i', 0)\n",
    "        ps_count = manager.Value('i', 0)\n",
    "        lock = manager.RLock()\n",
    "        # get network\n",
    "        net = az.Network()\n",
    "        net.share_memory()\n",
    "        collectors = []\n",
    "        for i in range(collect_no_net_procs):\n",
    "            c = mp.Process(target=collect_data_no_net,\n",
    "                           args=(i, buffer, index, lock,\n",
    "                                 buffer_size, ps_count))\n",
    "            c.start()\n",
    "            collectors.append(c)\n",
    "        trainer = mp.Process(target=train_process,\n",
    "                             args=(4, buffer, net,\n",
    "                                   global_step, ps_count))\n",
    "        trainer.start()\n",
    "        # join collectors before starting more\n",
    "        for c in collectors:\n",
    "            c.join()\n",
    "        collectors.clear()\n",
    "        # start data collectors with network\n",
    "        for i in range(collect_procs):\n",
    "            c = mp.Process(target=collect_data,\n",
    "                           args=(i, buffer, index, lock,\n",
    "                                 buffer_size, net, ps_count))\n",
    "            c.start()\n",
    "            collectors.append(c)\n",
    "        for c in collectors:\n",
    "            c.join()\n",
    "        print('all collectors are joined')\n",
    "        trainer.join()\n",
    "        print('trainer is joined')\n",
    "        buffer_list = list(buffer)  # save a non-shared copy\n",
    "        print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that sharing the neural network behaves as expected! Training updates the weights, and those updated weights are reflected in each of the data collection processes. Neat!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
