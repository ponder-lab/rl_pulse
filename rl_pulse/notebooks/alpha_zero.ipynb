{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero implementation for pulse sequence design\n",
    "_Will Kaufman, December 2020_\n",
    "\n",
    "[Dalgaard et. al. (2020)](https://www.nature.com/articles/s41534-019-0241-0) applied this approach to constructing shaped pulses (as I understand it), but in theory this should be as applicable to pulse sequence design, if not more so. The original [AlphaZero paper](https://science.sciencemag.org/content/362/6419/1140.full) and the [AlphaGo Zero paper](https://www.nature.com/articles/nature24270) are useful resources.\n",
    "\n",
    "The general idea behind AlphaZero (as I understand it) is to do a \"smart\" tree search that balances previous knowledge (the policy), curiosity in unexplored branches, and high-value branches. My thought is that this can be improved with AHT (i.e. knowing that by the end of the pulse sequence, the pulse sequence must be cyclic (the overall frame transformation must be identity) and there must be equal times spent on each axis). This will provide a hard constraint that will (hopefully) speed up search.\n",
    "\n",
    "## System installation\n",
    "\n",
    "Make sure the following packages are installed\n",
    "\n",
    "- `numpy`\n",
    "- `scipy`\n",
    "- `qutip`\n",
    "- `pytorch`\n",
    "- `tensorboard`\n",
    "\n",
    "## TODO\n",
    "- [ ] Collect all hyperparameters up top or in config (e.g. how many pulse sequences to collect data from)\n",
    "- [ ] Speed up LSTM (save hidden state, batch parallel pulse sequences, other?)\n",
    "- [ ] Figure out GPU utilization (if I can...)\n",
    "- [ ] Look into collecting training data and training continuously\n",
    "- [ ] Change dirichlet noise to match number of possible moves (5 for now, eventually 24)\n",
    "- [ ] Dynamically figure out how many CPUs there are available, and set pool to use that\n",
    "- [ ] Mess around with hyperparameters (e.g. in config object), see if performance improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- [ ] Add other changes on github project page (lots of documenting algo run)\n",
    "- [ ] Run it on Discovery, hope it works!\n",
    "- [ ] Clean up code, add tests, make sure everything is working as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import random\n",
    "from time import sleep\n",
    "import qutip as qt\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "import pulse_sequences as ps\n",
    "import alpha_zero as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pulse_sequences' from '/Users/willkaufman/Projects/rl_pulse/rl_pulse/pulse_sequences.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(az)\n",
    "importlib.reload(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_no_net_procs = 2  # 15\n",
    "collect_no_net_count = 5  # 700\n",
    "collect_procs = 2  # 15\n",
    "collect_count = 2  # 1000\n",
    "\n",
    "buffer_size = int(1e6)  # 1e6\n",
    "batch_size = 64  # 2048\n",
    "num_iters = int(1e2)  # 800e3\n",
    "\n",
    "max_sequence_length = 48\n",
    "\n",
    "print_every = 1  # 100\n",
    "save_every = 10  # 1000\n",
    "\n",
    "reward_threshold = 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the spin system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 1e-2  # time is relative to chemical shift strength\n",
    "pulse_width = 1e-3\n",
    "N = 3  # number of spins\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y, Z = ps.get_collective_spin(N)\n",
    "# Hsys_ensemble = [ps.get_Hsys(N) for _ in range(ensemble_size)]\n",
    "# pulses_ensemble = [\n",
    "#     ps.get_pulses(H, X, Y, Z, pulse_width, delay, rot_error=0.01) for H in Hsys_ensemble\n",
    "# ]\n",
    "# Utarget = qt.identity(Hsys_ensemble[0].dims[0])\n",
    "Utarget = qt.tensor([qt.identity(2)] * N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smarter search with MCTS\n",
    "\n",
    "Following the [supplementary materials description under \"Search\"](https://science.sciencemag.org/content/sci/suppl/2018/12/05/362.6419.1140.DC1/aar6404-Silver-SM.pdf) to do rollouts and backpropagate information. All of the relevant code for the alpha zero algorithm is in alpha_zero.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of saving data in a reasonable way (and using RNN), the state is represented by a sequence, where 0 indicates the start of sequence, and 1-5 are the possible pulses (1: delay, 2: x, etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = az.make_sequence(az.Config(), ps.PulseSequenceConfig(Utarget))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill replay buffer with inital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_no_net(proc_num, queue, ps_count, global_step, lock):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        proc_num: Which process number this is (for debug purposes)\n",
    "        queue (Queue): A queue to add the statistics gathered\n",
    "            from the MCTS rollouts.\n",
    "        ps_count (Value): Shared count of how many pulse sequences have\n",
    "            been constructed\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'collecting data without network ({proc_num})')\n",
    "    config = az.Config()\n",
    "    ps_config = ps.PulseSequenceConfig(N=N, ensemble_size=ensemble_size,\n",
    "                                       max_sequence_length=max_sequence_length,\n",
    "                                       Utarget=Utarget,\n",
    "                                       pulse_width=pulse_width, delay=delay)\n",
    "    for i in range(collect_no_net_count):\n",
    "        ps_config.reset()\n",
    "        output = az.make_sequence(config, ps_config, network=None,\n",
    "                                  rng=ps_config.rng)\n",
    "        if output[-1][2] > reward_threshold:\n",
    "            print(datetime.now(),\n",
    "                  f'candidate pulse sequence from {proc_num}',\n",
    "                  output[-1])\n",
    "        with lock:\n",
    "            queue.put(output)\n",
    "            ps_count.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with mp.Manager() as manager:\n",
    "#         buffer = manager.list()  #[None] * buffer_size\n",
    "#         index = manager.Value(typecode='i', value=0)\n",
    "#         ps_count = manager.Value(typecode='i', value=0)\n",
    "#         lock = manager.RLock()\n",
    "#         workers = []\n",
    "#         for i in range(4):\n",
    "#             workers.append(mp.Process(target=collect_data_no_net,\n",
    "#                                       args=(i, buffer, index, lock,\n",
    "#                                             buffer_size, ps_count)))\n",
    "#             workers[-1].start()\n",
    "#         for w in workers:\n",
    "#             w.join()\n",
    "#         print('done gathering initial data!')\n",
    "#         l = list(buffer)  # to save a non-shared copy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing networks with replay buffer data\n",
    "\n",
    "See [this doc](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) for writing training loss to tensorboard data, and [this doc](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference) for saving/loading models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "Setting up this algorithm to run in parallel is quite important. I'm using [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) to handle the parallelism, and it looks like pytorch also has a similar API for moving Tensors around. With 2 processors on my laptop, speedup is about 90% (not bad...).\n",
    "\n",
    "Want to set random seed for each process, otherwise you end up getting all the same results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(proc_num, queue, net, ps_count, global_step, lock):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        queue (Queue): A queue to add the statistics gathered\n",
    "            from the MCTS rollouts.\n",
    "        ps_count (Value): A shared count of how many pulse sequences have been\n",
    "            constructed so far\n",
    "    \"\"\"\n",
    "    print(datetime.now(), f'collecting data ({proc_num})')\n",
    "    config = az.Config()\n",
    "    config.num_simulations = 250\n",
    "    ps_config = ps.PulseSequenceConfig(Utarget=Utarget, N=N,\n",
    "                                       ensemble_size=ensemble_size,\n",
    "                                       max_sequence_length=max_sequence_length,\n",
    "                                       pulse_width=pulse_width, delay=delay)\n",
    "    while global_step.value < num_iters:\n",
    "        ps_config.reset()\n",
    "        output = az.make_sequence(config, ps_config, network=net,\n",
    "                                  rng=ps_config.rng)\n",
    "        if output[-1][2] > reward_threshold:\n",
    "            print(datetime.now(),\n",
    "                  f'candidate pulse sequence from {proc_num}',\n",
    "                  output[-1])\n",
    "        with lock:\n",
    "            queue.put(output)\n",
    "            ps_count.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     with mp.Manager() as manager:\n",
    "#         buffer = manager.list()  #[None] * 500\n",
    "#         index = manager.Value(typecode='i', value=0)\n",
    "#         lock = manager.RLock()\n",
    "#         # get network\n",
    "#         net = az.Network()\n",
    "#         net.share_memory()\n",
    "#         workers = []\n",
    "#         for i in range(4):\n",
    "#             workers.append(mp.Process(target=collect_data,\n",
    "#                                       args=(i, buffer, index, lock, buffer_size, net)))\n",
    "#             workers[-1].start()\n",
    "#         for w in workers:\n",
    "#             w.join()\n",
    "#         print('done gathering data!')\n",
    "#         l = list(buffer)  # save a non-shared copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(queue, net, global_step, ps_count, lock):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        queue (Queue): A queue to add the statistics gathered\n",
    "            from the MCTS rollouts.\n",
    "        global_step (mp.managers.Value): Counter to keep track\n",
    "            of training iterations\n",
    "        writer (SummaryWriter): Write losses to log\n",
    "    \"\"\"\n",
    "    writer = SummaryWriter()\n",
    "    net_optimizer = optim.Adam(net.parameters(),)\n",
    "    # construct replay buffer locally\n",
    "    buffer = []\n",
    "    index = 0\n",
    "    i = 0\n",
    "    while global_step.value < num_iters:  # number of training iterations\n",
    "        if i % save_every == 0:\n",
    "            print(datetime.now(), 'saving network...')\n",
    "            # save network parameters to file\n",
    "            if not os.path.exists('network'):\n",
    "                os.makedirs('network')\n",
    "            torch.save(net.state_dict(), f'network/{i:07.0f}-network')\n",
    "        # check if queue has new data to add to replay buffer\n",
    "        with lock:\n",
    "            while not queue.empty():\n",
    "                new_stats = queue.get()\n",
    "                new_stats = az.convert_stats_to_tensors(new_stats)\n",
    "                for stat in new_stats:\n",
    "                    if len(buffer) < buffer_size:\n",
    "                        buffer.append(stat)\n",
    "                    else:\n",
    "                        buffer[index] = stat\n",
    "                    index = index + 1 if index < buffer_size - 1 else 0\n",
    "        # carry on with training\n",
    "        if len(buffer) < batch_size:\n",
    "            print(datetime.now(), 'not enough data yet, sleeping...')\n",
    "            sleep(5)\n",
    "            continue\n",
    "#         elif len(buffer) < 1e4:\n",
    "#             sleep(.5)  # put on the brakes a bit, don't tear through the data\n",
    "        net_optimizer.zero_grad()\n",
    "        # sample minibatch from replay buffer\n",
    "        minibatch = random.sample(buffer, batch_size)\n",
    "        states, probabilities, values = zip(*minibatch)\n",
    "        probabilities = torch.stack(probabilities)\n",
    "        values = torch.stack(values)\n",
    "        packed_states = az.pad_and_pack(states)\n",
    "        # evaluate network\n",
    "        policy_outputs, value_outputs, _ = net(packed_states)\n",
    "        policy_loss = -1 / \\\n",
    "            len(states) * torch.sum(probabilities * torch.log(policy_outputs))\n",
    "        value_loss = F.mse_loss(value_outputs, values)\n",
    "        loss = policy_loss + value_loss\n",
    "        loss.backward()\n",
    "        net_optimizer.step()\n",
    "        # write losses to log\n",
    "        writer.add_scalar('training_policy_loss',\n",
    "                          policy_loss, global_step=global_step.value)\n",
    "        writer.add_scalar('training_value_loss',\n",
    "                          value_loss, global_step=global_step.value)\n",
    "        # every 10 iterations, add histogram of replay buffer values\n",
    "        # and save network to file...\n",
    "        if i % print_every == 0:\n",
    "            print(datetime.now(), f'updated network (iteration {i})',\n",
    "                  f'pulse_sequence_count: {ps_count.value}')\n",
    "            _, _, values = zip(*list(buffer))\n",
    "            values = torch.stack(values).squeeze()\n",
    "            writer.add_histogram('buffer_values', values,\n",
    "                                 global_step=global_step.value)\n",
    "            writer.add_scalar('pulse_sequence_count', ps_count.value,\n",
    "                              global_step.value)\n",
    "        with lock:\n",
    "            global_step.value += 1\n",
    "        i += 1\n",
    "        sleep(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-29 13:01:10.587632 2021-01-29 13:01:10.590961collecting data without network (0) \n",
      "collecting data without network (1)\n",
      "2021-01-29 13:01:10.659935 saving network...\n",
      "now the buffer has length 0\n",
      "2021-01-29 13:01:10.774018 not enough data yet, sleeping...\n",
      "0 starting\n",
      "1 starting\n",
      "1 made sequence\n",
      "1 added it to queue\n",
      "2021-01-29 13:01:15.828551 1saving network... \n",
      "startingunloading the queue...\n",
      "\n",
      "now the buffer has length 48\n",
      "2021-01-29 13:01:15.944928 not enough data yet, sleeping...\n",
      "0 made sequence\n",
      "0 added it to queue\n",
      "0 starting\n",
      "1 made sequence\n",
      "1 added it to queue\n",
      "2021-01-29 13:01:20.9587621  saving network...starting\n",
      "\n",
      "unloading the queue...\n",
      "unloading the queue...\n",
      "now the buffer has length 144\n",
      "2021-01-29 13:01:21.180944 updated network (iteration 0) pulse_sequence_count: 3\n",
      "now the buffer has length 144\n",
      "0 made sequence\n",
      "0 added it to queue\n",
      "0 starting\n",
      "2021-01-29 13:01:21.526627 updated network (iteration 1) pulse_sequence_count: 4\n",
      "unloading the queue...\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:21.790189 updated network (iteration 2) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:22.017417 updated network (iteration 3) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:22.225179 updated network (iteration 4) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:22.443520 updated network (iteration 5) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:22.786051 updated network (iteration 6) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:23.086470 updated network (iteration 7) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:23.361213 updated network (iteration 8) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:23.598258 updated network (iteration 9) pulse_sequence_count: 4\n",
      "2021-01-29 13:01:23.809867 saving network...\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:24.001454 updated network (iteration 10) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:24.272726 updated network (iteration 11) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:24.530132 updated network (iteration 12) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:24.779405 updated network (iteration 13) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:24.984537 updated network (iteration 14) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:25.226918 updated network (iteration 15) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:25.431112 updated network (iteration 16) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:25.734580 updated network (iteration 17) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:25.940550 updated network (iteration 18) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:26.356691 updated network (iteration 19) pulse_sequence_count: 4\n",
      "2021-01-29 13:01:26.523045 saving network...\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:26.695834 updated network (iteration 20) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:27.019154 updated network (iteration 21) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:27.291319 updated network (iteration 22) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:27.533804 updated network (iteration 23) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:27.788173 updated network (iteration 24) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:28.071884 updated network (iteration 25) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:28.310895 updated network (iteration 26) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:28.634778 updated network (iteration 27) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:28.853221 updated network (iteration 28) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:29.078569 updated network (iteration 29) pulse_sequence_count: 4\n",
      "2021-01-29 13:01:29.202998 saving network...\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:29.369992 updated network (iteration 30) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:29.597447 updated network (iteration 31) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:29.892784 updated network (iteration 32) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:30.117980 updated network (iteration 33) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:30.413745 updated network (iteration 34) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:30.658529 updated network (iteration 35) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:30.908171 updated network (iteration 36) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:31.276446 updated network (iteration 37) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:31.511089 updated network (iteration 38) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:31.834663 updated network (iteration 39) pulse_sequence_count: 4\n",
      "2021-01-29 13:01:31.994714 saving network...\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:32.154548 updated network (iteration 40) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:32.481241 updated network (iteration 41) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:32.728972 updated network (iteration 42) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:33.049738 updated network (iteration 43) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:33.285403 updated network (iteration 44) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:33.542088 updated network (iteration 45) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:33.792265 updated network (iteration 46) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:34.006152 updated network (iteration 47) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:34.251423 updated network (iteration 48) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:34.468302 updated network (iteration 49) pulse_sequence_count: 4\n",
      "2021-01-29 13:01:34.595399 saving network...\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:34.821277 updated network (iteration 50) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:35.029598 updated network (iteration 51) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:35.229187 updated network (iteration 52) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:35.471256 updated network (iteration 53) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:35.685981 updated network (iteration 54) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:35.891773 updated network (iteration 55) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:36.099114 updated network (iteration 56) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:36.370075 updated network (iteration 57) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:36.584726 updated network (iteration 58) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:36.783073 updated network (iteration 59) pulse_sequence_count: 4\n",
      "2021-01-29 13:01:36.907978 saving network...\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:37.034401 updated network (iteration 60) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:37.357488 updated network (iteration 61) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:37.588038 updated network (iteration 62) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:37.863063 updated network (iteration 63) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:38.208641 updated network (iteration 64) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "2021-01-29 13:01:38.608101 updated network (iteration 65) pulse_sequence_count: 4\n",
      "now the buffer has length 192\n",
      "1 made sequence\n",
      "1 added it to queue\n",
      "1 starting\n",
      "2021-01-29 13:01:38.973194 updated network (iteration 66) pulse_sequence_count: 5\n",
      "0 unloading the queue...\n",
      "made sequence\n",
      "now the buffer has length 0240\n",
      " added it to queue\n",
      "0 starting\n",
      "2021-01-29 13:01:39.389397 updated network (iteration 67) pulse_sequence_count: 6\n",
      "unloading the queue...\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:39.685451 updated network (iteration 68) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:39.896727 updated network (iteration 69) pulse_sequence_count: 6\n",
      "2021-01-29 13:01:40.027300 saving network...\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:40.217956 updated network (iteration 70) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:40.487521 updated network (iteration 71) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:40.825654 updated network (iteration 72) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:41.088860 updated network (iteration 73) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:41.333581 updated network (iteration 74) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:41.542643 updated network (iteration 75) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:41.776665 updated network (iteration 76) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:41.983883 updated network (iteration 77) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:42.294973 updated network (iteration 78) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:42.526424 updated network (iteration 79) pulse_sequence_count: 6\n",
      "2021-01-29 13:01:42.762784 saving network...\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:42.959642 updated network (iteration 80) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:43.175727 updated network (iteration 81) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:43.462349 updated network (iteration 82) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:43.800544 updated network (iteration 83) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:44.075204 updated network (iteration 84) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:44.276433 updated network (iteration 85) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:44.514892 updated network (iteration 86) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:44.758891 updated network (iteration 87) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:45.000802 updated network (iteration 88) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:45.339095 updated network (iteration 89) pulse_sequence_count: 6\n",
      "2021-01-29 13:01:45.471011 saving network...\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:45.661988 updated network (iteration 90) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:45.908898 updated network (iteration 91) pulse_sequence_count: 6\n",
      "now the buffer has length 288\n",
      "2021-01-29 13:01:46.173182 updated network (iteration 92) pulse_sequence_count: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-66:\n",
      "Process Process-64:\n",
      "Process Process-65:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-3c202e8e1979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# join collectors before starting more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mcollectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# start data collectors with network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-62-5a51f31a1de2>\", line 72, in train_process\n",
      "    writer.add_scalar('pulse_sequence_count', ps_count.value,\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/managers.py\", line 1138, in get\n",
      "    return self._callmethod('get')\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/managers.py\", line 819, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-56-1b15884dc3e1>\", line 20, in collect_data_no_net\n",
      "    rng=ps_config.rng)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 499, in make_sequence\n",
      "    sequence_funcs=sequence_funcs)\n",
      "  File \"<ipython-input-56-1b15884dc3e1>\", line 20, in collect_data_no_net\n",
      "    rng=ps_config.rng)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 499, in make_sequence\n",
      "    sequence_funcs=sequence_funcs)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 303, in run_mcts\n",
      "    sequence_funcs=sequence_funcs)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 303, in run_mcts\n",
      "    sequence_funcs=sequence_funcs)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 330, in evaluate\n",
      "    policy = np.ones((ps_config.num_pulses,)) / ps_config.num_pulses\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 331, in evaluate\n",
      "    valid_pulses = get_valid_pulses(sequence_tuple)\n",
      "  File \"/Users/willkaufman/Projects/rl_pulse/rl_pulse/alpha_zero.py\", line 471, in get_valid_pulses\n",
      "    if (counts <= ps_config.max_sequence_length / 6).all():\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/willkaufman/opt/anaconda3/envs/rl_pulse/lib/python3.7/site-packages/numpy/core/_methods.py\", line 57, in _all\n",
      "    return umr_all(a, axis, dtype, out, keepdims)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    with mp.Manager() as manager:\n",
    "        queue = manager.Queue()\n",
    "        global_step = manager.Value('i', 0)\n",
    "        ps_count = manager.Value('i', 0)\n",
    "        lock = manager.Lock()\n",
    "        # get network\n",
    "        net = az.Network()\n",
    "        net.share_memory()\n",
    "        collectors = []\n",
    "        for i in range(collect_no_net_procs):\n",
    "            c = mp.Process(target=collect_data_no_net,\n",
    "                           args=(i, queue, ps_count, global_step, lock))\n",
    "            c.start()\n",
    "            collectors.append(c)\n",
    "        trainer = mp.Process(target=train_process,\n",
    "                             args=(queue, net,\n",
    "                                   global_step, ps_count, lock))\n",
    "        trainer.start()\n",
    "        # join collectors before starting more\n",
    "        for c in collectors:\n",
    "            c.join()\n",
    "        collectors.clear()\n",
    "        # start data collectors with network\n",
    "        for i in range(collect_procs):\n",
    "            c = mp.Process(target=collect_data,\n",
    "                           args=(i, queue, net, ps_count, global_step, lock))\n",
    "            c.start()\n",
    "            collectors.append(c)\n",
    "        for c in collectors:\n",
    "            c.join()\n",
    "        print('all collectors are joined')\n",
    "        trainer.join()\n",
    "        print('trainer is joined')\n",
    "        print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that sharing the neural network behaves as expected! Training updates the weights, and those updated weights are reflected in each of the data collection processes. Neat!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
