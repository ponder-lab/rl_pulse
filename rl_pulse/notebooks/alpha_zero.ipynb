{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero implementation for pulse sequence design\n",
    "_Will Kaufman, December 2020_\n",
    "\n",
    "[Dalgaard et. al. (2020)](https://www.nature.com/articles/s41534-019-0241-0) applied this approach to constructing shaped pulses (as I understand it), but in theory this should be as applicable to pulse sequence design, if not more so. The original [AlphaZero paper](https://science.sciencemag.org/content/362/6419/1140.full) is here.\n",
    "\n",
    "The general idea behind AlphaZero (as I understand it) is to do a \"smart\" tree search that balances previous knowledge (the policy), curiosity in unexplored branches, and high-value branches. My thought is that this can be improved with AHT (i.e. knowing that by the end of the pulse sequence, the pulse sequence must be cyclic (the overall frame transformation must be identity) and there must be equal times spent on each axis). This will provide a hard constraint that will (hopefully) speed up search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "from random import sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "import pulse_sequences as ps\n",
    "import alpha_zero as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pulse_sequences' from '/Users/willkaufman/Projects/rl_pulse/rl_pulse/pulse_sequences.py'>"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(az)\n",
    "importlib.reload(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the spin system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 1e-2  # time is relative to chemical shift strength\n",
    "pulse_width = 5e-3\n",
    "N = 3  # number of spins\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Z = ps.get_collective_spin(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hsys_ensemble = [ps.get_Hsys(N) for _ in range(ensemble_size)]\n",
    "pulses_ensemble = [\n",
    "    ps.get_pulses(H, X, Y, Z, pulse_width, delay, rot_error=0.01) for H in Hsys_ensemble\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utarget = qt.identity(Hsys_ensemble[0].dims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Hamiltonian theory\n",
    "\n",
    "To keep track of the average Hamiltonian (to lowest order), I'm defining a frame matrix and applying rotation matrices to the frame matrix, then determining how $I_z$ transforms during the pulse sequence. The last row in the frame matrix corresponds to the current transformed value of $I_z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 8, 8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.count_axes(ps.yxx48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_valid_time_suspension_pulses([0,1,1,], len(ps.pulse_names), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree search\n",
    "\n",
    "Define nodes that can be used for tree search, with additional constraints that the lowest-order average Hamiltonian matches the desired Hamiltonian.\n",
    "\n",
    "(deleted code that implemented tree search with constraints, see GitHub repo commits on 12/8 for code)\n",
    "\n",
    "For 12-pulse sequences, calculated 16 branches at depth 4 in a minute, so about 1 every 4 seconds. At depth 4 there are $5^4 = 625$ branches, so that'll take $4 * 625 = 41$ hours to fully run. Alternatively, you can generate random pulse sequences until there's one that has the proper lowest-order average and cyclic property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smarter search with MCTS\n",
    "\n",
    "Following the [supplementary materials description under \"Search\"](https://science.sciencemag.org/content/sci/suppl/2018/12/05/362.6419.1140.DC1/aar6404-Silver-SM.pdf) to do rollouts and backpropagate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = az.Config()\n",
    "config.num_simulations = 500\n",
    "ps_config = ps.PulseSequenceConfig(N, ensemble_size, pulse_width, delay, 6, Utarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext snakeviz\n",
    "# %snakeviz -t az.make_sequence(config, ps_config, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = az.make_sequence(config, ps_config, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps_config.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Inspired by [this pytorch tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []\n",
    "        self.position = 0\n",
    "    \n",
    "    def add(self, data):\n",
    "        \"\"\"Save to replay buffer\n",
    "        \"\"\"\n",
    "        if len(self) < self.capacity:\n",
    "            self.buffer.append(data)\n",
    "        else:\n",
    "            self.buffer[self.position] = data\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "    \n",
    "    def sample(self, batch_size=1):\n",
    "        if batch_size > len(self):\n",
    "            raise ValueError(f'batch_size of {batch_size} should be'\n",
    "                             + f'less than buffer size of {len(self)}')\n",
    "        return sample(self.buffer, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = ReplayBuffer(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = az.Config()\n",
    "config.num_simulations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of saving data in a reasonable way (and using RNN), the state is represented by a sequence, where 0 indicates the start of sequence, and 1-5 are the possible pulses (1: delay, 2: x, etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating pulse sequence 0\n",
      "creating pulse sequence 1\n",
      "creating pulse sequence 2\n",
      "creating pulse sequence 3\n",
      "creating pulse sequence 4\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(f'creating pulse sequence {_}')\n",
    "    ps_config = ps.PulseSequenceConfig(N, ensemble_size, pulse_width, delay, 48, Utarget)\n",
    "    stats = az.make_sequence(config, ps_config, None)\n",
    "    for s in stats:\n",
    "        state = torch.Tensor(s[0]) + 1\n",
    "        state = torch.cat([torch.Tensor([0]), state])\n",
    "        state = F.one_hot(state.long(), 6).float()\n",
    "        probs = torch.Tensor(s[1])\n",
    "        value = torch.Tensor([s[2]])\n",
    "        rb.add((state,\n",
    "                probs,\n",
    "                value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks for policy, value estimation\n",
    "\n",
    "Batched tensors have shape `B * T * ...` where `B` is batch size and `T` is the timestep. Different from default behavior, but more intuitive to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, input_size=6, lstm_size=16, output_size=6):\n",
    "        super(Policy, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=lstm_size,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        self.fc1 = nn.Linear(lstm_size, output_size)\n",
    "    \n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        \"\"\"Calculates the policy from state x\n",
    "        \n",
    "        Args:\n",
    "            x: The state of the pulse sequence. Either a tensor with \n",
    "                shape B*T*(num_actions + 1), or a packed sequence of states.\n",
    "        \"\"\"\n",
    "        if h0 is None or c0 is None:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x, (h0, c0))\n",
    "        if type(x) is torch.Tensor:\n",
    "            x = x[:, -1, :]\n",
    "        elif type(x) is nn.utils.rnn.PackedSequence:\n",
    "            # x is PackedSequence, need to get last timestep from each\n",
    "            x, lengths = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "            idx = (\n",
    "                lengths.long() - 1\n",
    "            ).view(\n",
    "                -1, 1\n",
    "            ).expand(\n",
    "                len(lengths), x.size(2)\n",
    "            ).unsqueeze(1)\n",
    "            x = x.gather(1, idx).squeeze(1)\n",
    "        x = F.softmax(self.fc1(x), dim=1)\n",
    "        return x, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Policy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(p.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "seq_length = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = rb.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [i[0] for i in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [s.size(0) for s in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_states = nn.utils.rnn.pack_padded_sequence(\n",
    "    nn.utils.rnn.pad_sequence(states, batch_first=True),\n",
    "    lengths, enforce_sorted=False, batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (h, c) = p(packed_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the output is the same for packed and individual inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_individual = torch.cat([p(s.unsqueeze(0))[0] for s in states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2197e-07, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(output - output_individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the hidden and cell states work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1, (h1, c1) = p(packed_states, h0=h, c0=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubled_states = [\n",
    "    torch.cat([s, s])\n",
    "    for s in states\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [],
   "source": [
    "doubled_lengths = [s.size(0) for s in doubled_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_doubles = nn.utils.rnn.pack_padded_sequence(\n",
    "    nn.utils.rnn.pad_sequence(doubled_states, batch_first=True),\n",
    "    doubled_lengths, enforce_sorted=False, batch_first=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2, (h2, c2) = p(packed_doubles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5810e-08, grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(output2 - output1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize policy based on target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = 0 # TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(80.8050, grad_fn=<NegBackward>)\n",
      "tensor(77.2775, grad_fn=<NegBackward>)\n",
      "tensor(73.8556, grad_fn=<NegBackward>)\n",
      "tensor(71.4682, grad_fn=<NegBackward>)\n",
      "tensor(69.1231, grad_fn=<NegBackward>)\n",
      "tensor(67.9690, grad_fn=<NegBackward>)\n",
      "tensor(66.3810, grad_fn=<NegBackward>)\n",
      "tensor(65.5521, grad_fn=<NegBackward>)\n",
      "tensor(65.0454, grad_fn=<NegBackward>)\n",
      "tensor(65.2894, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    outputs, (h, c) = p(inputs)\n",
    "    loss = -torch.sum(targets * torch.log(outputs))\n",
    "    if _ % 100 == 0:\n",
    "        print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- [ ] Value network (below)\n",
    "- [ ] Bring it all together with MCTS...\n",
    "- [ ] Set up Discovery environment\n",
    "- [ ] Run it and (hopefully) rejoice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value(nn.Module):\n",
    "    \"\"\"TODO change all below, just copied from Policy network\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=6, lstm_size=16, output_size=6):\n",
    "        super(Policy, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size,\n",
    "                            hidden_size=lstm_size,\n",
    "                            num_layers=1,\n",
    "                            batch_first=True)\n",
    "        self.fc1 = nn.Linear(lstm_size, output_size)\n",
    "    \n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        \"\"\"Calculates the policy from state x\n",
    "        \n",
    "        Args:\n",
    "            x: The state of the pulse sequence. Either a tensor with \n",
    "                shape B*T*(num_actions + 1), or a packed sequence of states.\n",
    "        \"\"\"\n",
    "        if h0 is None or c0 is None:\n",
    "            x, (h, c) = self.lstm(x)\n",
    "        else:\n",
    "            x, (h, c) = self.lstm(x, (h0, c0))\n",
    "        if type(x) is torch.Tensor:\n",
    "            x = x[:, -1, :]\n",
    "        elif type(x) is nn.utils.rnn.PackedSequence:\n",
    "            # x is PackedSequence, need to get last timestep from each\n",
    "            x, lengths = nn.utils.rnn.pad_packed_sequence(x, batch_first=True)\n",
    "            idx = (\n",
    "                lengths.long() - 1\n",
    "            ).view(\n",
    "                -1, 1\n",
    "            ).expand(\n",
    "                len(lengths), x.size(2)\n",
    "            ).unsqueeze(1)\n",
    "            x = x.gather(1, idx).squeeze(1)\n",
    "        x = F.softmax(self.fc1(x), dim=1)\n",
    "        return x, (h, c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
