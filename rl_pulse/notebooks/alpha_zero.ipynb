{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaZero implementation for pulse sequence design\n",
    "_Will Kaufman, December 2020_\n",
    "\n",
    "[Dalgaard et. al. (2020)](https://www.nature.com/articles/s41534-019-0241-0) applied this approach to constructing shaped pulses (as I understand it), but in theory this should be as applicable to pulse sequence design, if not more so. The original [AlphaZero paper](https://science.sciencemag.org/content/362/6419/1140.full) is here.\n",
    "\n",
    "The general idea behind AlphaZero (as I understand it) is to do a \"smart\" tree search that balances previous knowledge (the policy), curiosity in unexplored branches, and high-value branches. My thought is that this can be improved with AHT (i.e. knowing that by the end of the pulse sequence, the pulse sequence must be cyclic (the overall frame transformation must be identity) and there must be equal times spent on each axis). This will provide a hard constraint that will (hopefully) speed up search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip as qt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "from random import sample\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "import pulse_sequences as ps\n",
    "import alpha_zero as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pulse_sequences' from '/Users/willkaufman/Projects/rl_pulse/rl_pulse/pulse_sequences.py'>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(az)\n",
    "importlib.reload(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the spin system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay = 1e-2  # time is relative to chemical shift strength\n",
    "pulse_width = 5e-3\n",
    "N = 3  # number of spins\n",
    "ensemble_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, Z = ps.get_collective_spin(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hsys_ensemble = [ps.get_Hsys(N) for _ in range(ensemble_size)]\n",
    "pulses_ensemble = [\n",
    "    ps.get_pulses(H, X, Y, Z, pulse_width, delay, rot_error=0.01) for H in Hsys_ensemble\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utarget = qt.identity(Hsys_ensemble[0].dims[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Hamiltonian theory\n",
    "\n",
    "To keep track of the average Hamiltonian (to lowest order), I'm defining a frame matrix and applying rotation matrices to the frame matrix, then determining how $I_z$ transforms during the pulse sequence. The last row in the frame matrix corresponds to the current transformed value of $I_z$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 8, 8]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.count_axes(ps.yxx48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.get_valid_time_suspension_pulses([0,1,1,], len(ps.pulse_names), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree search\n",
    "\n",
    "Define nodes that can be used for tree search, with additional constraints that the lowest-order average Hamiltonian matches the desired Hamiltonian.\n",
    "\n",
    "(deleted code that implemented tree search with constraints, see GitHub repo commits on 12/8 for code)\n",
    "\n",
    "For 12-pulse sequences, calculated 16 branches at depth 4 in a minute, so about 1 every 4 seconds. At depth 4 there are $5^4 = 625$ branches, so that'll take $4 * 625 = 41$ hours to fully run. Alternatively, you can generate random pulse sequences until there's one that has the proper lowest-order average and cyclic property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smarter search with MCTS\n",
    "\n",
    "Following the [supplementary materials description under \"Search\"](https://science.sciencemag.org/content/sci/suppl/2018/12/05/362.6419.1140.DC1/aar6404-Silver-SM.pdf) to do rollouts and backpropagate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = az.Config()\n",
    "config.num_simulations = 500\n",
    "ps_config = ps.PulseSequenceConfig(N, ensemble_size, pulse_width, delay, 6, Utarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext snakeviz\n",
    "# %snakeviz -t az.make_sequence(config, ps_config, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = az.make_sequence(config, ps_config, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps_config.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay buffer\n",
    "\n",
    "Inspired by [this pytorch tutorial](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb = az.ReplayBuffer(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = az.Config()\n",
    "config.num_simulations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of saving data in a reasonable way (and using RNN), the state is represented by a sequence, where 0 indicates the start of sequence, and 1-5 are the possible pulses (1: delay, 2: x, etc...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(config, ps_config, replay_buffer, network=None, num_iter=1):\n",
    "    \"\"\"Makes sequence using MCTS, then saves to replay buffer\n",
    "    \"\"\"\n",
    "    for _ in range(num_iter):\n",
    "        ps_config.reset()\n",
    "        stats = az.make_sequence(config, ps_config, network)\n",
    "        az.add_stats_to_buffer(stats, replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_training_data(config, ps_config, rb, num_iter=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTS with policy and value networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = az.Config()\n",
    "config.num_simulations = 100\n",
    "ps_config = ps.PulseSequenceConfig(N, ensemble_size=ensemble_size,\n",
    "                                   max_sequence_length=48, Utarget=Utarget,\n",
    "                                   pulse_width=pulse_width, delay=delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = az.Policy()\n",
    "v = az.Value()\n",
    "net = az.Network(p, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_config.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The snakeviz extension is already loaded. To reload it, use:\n",
      "  %reload_ext snakeviz\n",
      " \n",
      "*** Profile stats marshalled to file '/var/folders/_y/8j5pxws97d7clk4h9d6bjhtr0000gn/T/tmpoddonvv6'. \n",
      "Opening SnakeViz in a new tab...\n"
     ]
    }
   ],
   "source": [
    "%load_ext snakeviz\n",
    "%snakeviz -t az.make_sequence(config, ps_config, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = az.make_sequence(config, ps_config, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing networks with replay buffer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the above code seems to run, but boy does it run slowly... I'll probably want to gather a lot of data with random policy (no network) first, then train from there.\n",
    "\n",
    "TODO\n",
    "\n",
    "- [ ] Finish training loop: add stats to buffer, set up training functions\n",
    "- [ ] Look into multiprocessing, gathering training data and training continuously\n",
    "- [ ] Set up on Discovery and run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_optimizer = optim.Adam(p.parameters(), lr=1e-5)\n",
    "value_optimizer = optim.Adam(v.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_step(replay_buffer, policy, policy_optimizer, value, value_optimizer, num_iters=1, batch_size=64):\n",
    "    for i in range(num_iters):\n",
    "        if i % 10 == 0:\n",
    "            print(f'On iteration {i}...', end=' ')\n",
    "        minibatch = rb.sample(batch_size=batch_size)\n",
    "        states, probabilities, values = zip(*minibatch)\n",
    "        probabilities = torch.cat(probabilities).view(batch_size, -1)\n",
    "        values = torch.cat(values).view(batch_size, -1)\n",
    "        packed_states = az.pad_and_pack(states)\n",
    "        policy_outputs, __ = policy(packed_states)\n",
    "        policy_loss = -1 / len(states) * torch.sum(probabilities * torch.log(policy_outputs))\n",
    "        policy_loss.backward()\n",
    "        policy_optimizer.step()\n",
    "        # value optimization\n",
    "        value_outputs, __ = value(packed_states)\n",
    "        value_loss = F.mse_loss(value_outputs, values)\n",
    "        value_loss.backward()\n",
    "        value_optimizer.step()\n",
    "        if i % 10 == 0:\n",
    "            print(f'policy loss: {policy_loss:.05f}, value loss: {value_loss:.05f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On iteration 0... policy loss: 1.55268, value loss: 0.17206\n",
      "On iteration 10... policy loss: 1.56332, value loss: 0.12074\n",
      "On iteration 20... policy loss: 1.60301, value loss: 0.12086\n",
      "On iteration 30... policy loss: 1.57278, value loss: 0.10971\n",
      "On iteration 40... policy loss: 1.59487, value loss: 0.15085\n",
      "On iteration 50... policy loss: 1.57941, value loss: 0.11003\n",
      "On iteration 60... policy loss: 1.55052, value loss: 0.10016\n",
      "On iteration 70... policy loss: 1.54150, value loss: 0.12018\n",
      "On iteration 80... policy loss: 1.56801, value loss: 0.17147\n",
      "On iteration 90... policy loss: 1.52813, value loss: 0.09037\n",
      "On iteration 100... policy loss: 1.59216, value loss: 0.10013\n",
      "On iteration 110... policy loss: 1.58188, value loss: 0.09911\n",
      "On iteration 120... policy loss: 1.58390, value loss: 0.09990\n",
      "On iteration 130... policy loss: 1.55856, value loss: 0.14168\n",
      "On iteration 140... policy loss: 1.59692, value loss: 0.12039\n",
      "On iteration 150... policy loss: 1.56287, value loss: 0.13064\n",
      "On iteration 160... policy loss: 1.55194, value loss: 0.13028\n",
      "On iteration 170... policy loss: 1.55846, value loss: 0.10997\n",
      "On iteration 180... policy loss: 1.60037, value loss: 0.07874\n",
      "On iteration 190... policy loss: 1.57763, value loss: 0.08968\n",
      "On iteration 200... policy loss: 1.57677, value loss: 0.08977\n",
      "On iteration 210... policy loss: 1.58509, value loss: 0.13061\n",
      "On iteration 220... policy loss: 1.59608, value loss: 0.13130\n",
      "On iteration 230... policy loss: 1.57253, value loss: 0.09894\n",
      "On iteration 240... policy loss: 1.60993, value loss: 0.17114\n"
     ]
    }
   ],
   "source": [
    "optimize_step(rb, p, policy_optimizer, v, value_optimizer, num_iters=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
