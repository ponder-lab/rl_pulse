{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulse sequence design using evolutionary algorithms\n",
    "_Written by Will Kaufman, November 2020_\n",
    "\n",
    "This notebook tries to replicate results found in Pai Peng et. al.'s preprint.\n",
    "\n",
    "**TODO** fill in this introduction more!\n",
    "\n",
    "# TODO\n",
    "\n",
    "- [ ] see if multiprocessing works `if __name__ == '__main__'`\n",
    "- [ ] run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import qutip as qt\n",
    "import tensorflow as tf\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define algorithm hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 5\n",
    "population_size = 5\n",
    "num_generations = 5\n",
    "# TODO eventually fill in hyperparameters at top of doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "if not os.path.exists(os.path.join(\n",
    "    'logs', current_time, 'rewards'\n",
    ")):\n",
    "    os.makedirs(os.path.join(\n",
    "        'logs', current_time, 'rewards'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the spin system\n",
    "\n",
    "This sets the parameters of the system ($N$ spin-1/2 particles, which corresponds to a Hilbert space with dimension $2^N$). For the purposes of simulation, $\\hbar \\equiv 1$.\n",
    "\n",
    "The total internal Hamiltonian is given by\n",
    "$$\n",
    "H_\\text{int} = C H_\\text{dip} + \\sum_i^N \\delta_i I_z^{i}\n",
    "$$\n",
    "where $C$ is the coupling strength, $\\delta$ is the chemical shift strength (each spin is assumed to be identical), and $H_\\text{dip}$ is given by\n",
    "$$\n",
    "H_\\text{dip} = \\sum_{i,j}^N d_{i,j} \\left(3I_z^{i}I_z^{j} - \\mathbf{I}^{i} \\cdot \\mathbf{I}^{j}\\right)\n",
    "$$\n",
    "\n",
    "The target unitary transformation is a simple $\\pi/2$-pulse about the x-axis\n",
    "$$\n",
    "U_\\text{target} = \\exp\\left(-i \\frac{\\pi}{4} \\sum_j I_x^j \\right)\n",
    "$$\n",
    "\n",
    "<!-- Hamiltonian is set to be the 0th-order average Hamiltonian from the WHH-4 pulse sequence, which is designed to remove the dipolar interaction term from the internal Hamiltonian. The pulse sequence is $\\tau, \\overline{X}, \\tau, Y, \\tau, \\tau, \\overline{Y}, \\tau, X, \\tau$.\n",
    "The zeroth-order average Hamiltonian for the WAHUHA pulse sequence is\n",
    "$$\n",
    "H_\\text{WHH}^{(0)} = \\delta / 3 \\sum_i^N \\left( I_x^{i} + I_y^{i} + I_z^{i} \\right)\n",
    "$$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system(N=3, ):\n",
    "    # chemical_shifts = np.random.normal(scale=50, size=(N,))\n",
    "    # Hcs = sum(\n",
    "    #     [qt.tensor(\n",
    "    #         [qt.identity(2)]*i\n",
    "    #         + [chemical_shifts[i] * qt.sigmaz()]\n",
    "    #         + [qt.identity(2)]*(N-i-1)\n",
    "    #     ) for i in range(N)]\n",
    "    # )\n",
    "    dipolar_matrix = np.random.normal(scale=50, size=(N, N))\n",
    "    Hdip = sum([\n",
    "        dipolar_matrix[i, j] * (\n",
    "            2 * qt.tensor(\n",
    "                [qt.identity(2)]*i\n",
    "                + [qt.sigmaz()]\n",
    "                + [qt.identity(2)]*(j-i-1)\n",
    "                + [qt.sigmaz()]\n",
    "                + [qt.identity(2)]*(N-j-1)\n",
    "            )\n",
    "            - qt.tensor(\n",
    "                [qt.identity(2)]*i\n",
    "                + [qt.sigmax()]\n",
    "                + [qt.identity(2)]*(j-i-1)\n",
    "                + [qt.sigmax()]\n",
    "                + [qt.identity(2)]*(N-j-1)\n",
    "            )\n",
    "            - qt.tensor(\n",
    "                [qt.identity(2)]*i\n",
    "                + [qt.sigmay()]\n",
    "                + [qt.identity(2)]*(j-i-1)\n",
    "                + [qt.sigmay()]\n",
    "                + [qt.identity(2)]*(N-j-1)\n",
    "            )\n",
    "        )\n",
    "        for i in range(N) for j in range(i+1, N)\n",
    "    ])\n",
    "    # Hsys = Hcs + Hdip\n",
    "    Hsys = Hdip\n",
    "    X = sum(\n",
    "        [qt.tensor(\n",
    "            [qt.identity(2)]*i\n",
    "            + [qt.sigmax()]\n",
    "            + [qt.identity(2)]*(N-i-1)\n",
    "        ) for i in range(N)]\n",
    "    )\n",
    "    Y = sum(\n",
    "        [qt.tensor(\n",
    "            [qt.identity(2)]*i\n",
    "            + [qt.sigmay()]\n",
    "            + [qt.identity(2)]*(N-i-1)\n",
    "        ) for i in range(N)]\n",
    "    )\n",
    "    return Hsys, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hsys, X, Y = make_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the actions as a list of propagators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_actions(Hsys, X, Y, tau=5e-6, pulse_length=1e-7):\n",
    "    actions = [\n",
    "        # delay\n",
    "        qt.propagator(Hsys, tau),\n",
    "        # rotations\n",
    "        qt.propagator(Hsys, tau) * qt.propagator(X, np.pi / 4),\n",
    "        qt.propagator(Hsys, tau) * qt.propagator(Y, np.pi / 4),\n",
    "        qt.propagator(Hsys, tau) * qt.propagator(X, -np.pi / 4),\n",
    "        qt.propagator(Hsys, tau) * qt.propagator(Y, -np.pi / 4)\n",
    "    ]\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = make_actions(Hsys, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define actor and critic networks\n",
    "\n",
    "The observations of the system are sequences of control amplitudes that have been performed on the system (which most closely represents the knowledge of a typical experimental system). Both the actor and the critic (value) networks share an LSTM layer to convert the sequence of control amplitudes to a hidden state, and two dense layers. Separate policy and value \"heads\" are used for the two different networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_actor(num_actions=5):\n",
    "    stateful_lstm = tf.keras.layers.LSTM(64, stateful=True)\n",
    "    hidden1 = tf.keras.layers.Dense(64, activation=tf.keras.activations.relu)\n",
    "    hidden2 = tf.keras.layers.Dense(64, activation=tf.keras.activations.relu)\n",
    "    policy = tf.keras.layers.Dense(num_actions, activation=tf.keras.activations.softmax)\n",
    "    \n",
    "    actor = tf.keras.models.Sequential([\n",
    "        stateful_lstm,\n",
    "        hidden1,\n",
    "        hidden2,\n",
    "        policy\n",
    "    ])\n",
    "    actor.build(input_shape=(1, None, num_actions))\n",
    "    return actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = tf.reshape(\n",
    "#     tf.constant(\n",
    "#         [0,0,1,0,0]\n",
    "#     ), (1, 1, 5)\n",
    "# )\n",
    "\n",
    "# actor = make_actor()\n",
    "# actor(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_actor(actor, sequence_length=6):\n",
    "    actor.reset_states()\n",
    "    Hsys, X, Y = make_system()\n",
    "    actions = make_actions(Hsys, X, Y,\n",
    "                           tau=5e-06, pulse_length=1e-07)\n",
    "    propagator = qt.identity(Hsys.dims[0])\n",
    "    action = tf.zeros((1, 1, 5))\n",
    "    for _ in range(sequence_length):\n",
    "        # determine next action\n",
    "        probs = actor(action)\n",
    "        action_ind = tf.squeeze(tf.random.categorical(\n",
    "            tf.math.log(probs),\n",
    "            1\n",
    "        ))\n",
    "        action = tf.reshape(\n",
    "            tf.one_hot(\n",
    "                action_ind, num_actions, 1, 0),\n",
    "            shape=(1, 1, num_actions))\n",
    "        # apply next action\n",
    "        propagator = propagator * actions[action_ind]\n",
    "    # evaluate fidelity/reward\n",
    "    target = qt.identity(Hsys.dims[0])\n",
    "    fidelity = np.clip(np.abs(\n",
    "        (propagator.dag() * target).tr()\n",
    "        / qt.identity(Hsys.dims[0]).tr()\n",
    "    ), 0, 1)\n",
    "    reward = -np.log10(1 - fidelity + 1e-50)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewards = [evaluate_actor(actor) for _ in range(100)]\n",
    "# plt.hist(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_actor_mean(actor, sequence_length=6, n=10):\n",
    "    rewards = [\n",
    "        evaluate_actor(\n",
    "            actor,\n",
    "            sequence_length=sequence_length)\n",
    "        for _ in range(n)]\n",
    "    return np.nanmean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_actor(actor, strength=0.1, fraction=0.25):\n",
    "    weights = actor.get_weights()\n",
    "    new_weights = []\n",
    "    for w in weights:\n",
    "        shape = w.shape\n",
    "        ind = np.random.random(size=shape) < fraction\n",
    "        new_w = w * (1\n",
    "                     + ind\n",
    "                     * np.random.normal(scale=strength, size=shape))\n",
    "        new_weights.append(new_w)\n",
    "    actor.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = [make_actor() for _ in range(population_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_population(actors, num_elite=2, num_replace=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        num_elite: Number of best-performing actors that shouldn't\n",
    "            be modified.\n",
    "        num_replace: Number of worst-performing actors that should\n",
    "            be replaced by copies of other actors.\n",
    "    \"\"\"\n",
    "    description = ''\n",
    "    rewards = {}\n",
    "    # evaluate population\n",
    "    # with ProcessPoolExecutor() as pool:\n",
    "    #     for actor_ind, reward in enumerate(pool.map(evaluate_actor_mean, actors)):\n",
    "    #         rewards[actor_ind] = reward\n",
    "    for actor, reward in zip(actors, map(evaluate_actor_mean, actors)):\n",
    "        rewards[actor] = reward\n",
    "    # sort based on performance (best to worst)\n",
    "    actors = sorted(actors, key=lambda a: rewards[a], reverse=True)\n",
    "    rewards_list = list(rewards.values())\n",
    "    new_order = sorted(range(len(actors)),\n",
    "                       key=lambda a: rewards_list[a], reverse=True)\n",
    "    rewards = sorted(rewards_list, reverse=True)\n",
    "    description += ('new order of actors:\\t'\n",
    "                    + ', '.join([str(num) for num in new_order])\n",
    "                    + '\\n')\n",
    "    # replace worst-performing actors\n",
    "    actors[(-num_replace):] = [make_actor() for _ in range(num_replace)]\n",
    "    description += 'actors copied:\\t'\n",
    "    copied_ind = []\n",
    "    for i in range(num_replace):\n",
    "        copy_ind = np.random.choice(len(actors) - num_replace)\n",
    "        copied_ind.append(copy_ind)\n",
    "        actors[-(i+1)].set_weights(actors[copy_ind].get_weights())\n",
    "    description += ', '.join([str(num) for num in copied_ind]) + '\\n'\n",
    "    # mutate non-elite actors\n",
    "    for actor in actors[num_elite:]:\n",
    "        mutate_actor(actor)\n",
    "    return actors, rewards, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(5):\n",
    "#     actors, rewards, description = iterate_population(actors)\n",
    "#     print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on generation 0\n",
      "new order of actors:\t2, 0, 3, 4, 1\n",
      "actors copied:\t0\n",
      "\n",
      "on generation 1\n",
      "new order of actors:\t4, 1, 0, 3, 2\n",
      "actors copied:\t1\n",
      "\n",
      "on generation 2\n",
      "new order of actors:\t4, 3, 0, 1, 2\n",
      "actors copied:\t1\n",
      "\n",
      "on generation 3\n",
      "new order of actors:\t3, 0, 1, 4, 2\n",
      "actors copied:\t1\n",
      "\n",
      "on generation 4\n",
      "new order of actors:\t2, 4, 3, 1, 0\n",
      "actors copied:\t2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(num_generations):\n",
    "    print(f'on generation {_}')\n",
    "    actors, rewards, description = iterate_population(actors)\n",
    "    np.savetxt(os.path.join(\n",
    "        'logs', current_time, f'rewards/rewards-{_:05.0f}.txt'\n",
    "    ), rewards)\n",
    "    if _ % 10 == 0:\n",
    "        for i, actor in enumerate(actors[:5]):\n",
    "            actor.save_weights(os.path.join(\n",
    "                'logs', current_time, 'model', f'actor-{i}-{_:05.0f}'\n",
    "            ))\n",
    "    print(description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
